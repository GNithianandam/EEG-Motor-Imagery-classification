{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiF8-5csPI16",
        "outputId": "90902a82-fb63-4d90-a932-b3289a7c6170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.7/dist-packages (from mne) (1.6.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mne) (2.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mne) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mne) (4.64.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mne) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.21.6)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mne) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mne) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mne) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mne) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mne\n",
        "import mne\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import SpatialDropout2D\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "from tensorflow.keras.layers import Input, Flatten\n",
        "from tensorflow.keras.constraints import max_norm\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVu8GHKaPlPR",
        "outputId": "8c354628-f4fb-4c8e-93a9-40b1d965a4ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file='/content/drive/MyDrive/BCICIV_2a_gdf/A09T.gdf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bnzb37qwPl34",
        "outputId": "28cf0f42-e692-4e81-cbcf-4bec6281a46a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mne/io/edf/edf.py:1155: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "  etmode = np.fromstring(etmode, UINT8).tolist()[0]\n",
            "/usr/lib/python3.7/contextlib.py:119: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
            "  next(self.gen)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 4 - 40 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 4.00\n",
            "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
            "- Upper passband edge: 40.00 Hz\n",
            "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
            "- Filter length: 413 samples (1.652 sec)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.1s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25, 673328)\n",
            "Used Annotations descriptions: ['1023', '1072', '276', '277', '32766', '768', '769', '770', '771', '772']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    0.6s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "639\n",
            "72\n",
            "72\n",
            "71\n",
            "72\n",
            "(71, 22, 1000)\n",
            "(71, 22, 1000)\n",
            "(71, 22, 1000)\n",
            "(71, 22, 1000)\n",
            "(170, 22, 1000) (102, 22, 1000) (12, 22, 1000)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "raw=mne.io.read_raw_gdf(file, preload=True, stim_channel='auto', verbose=False)\n",
        "# Filter settings\n",
        "low_cut = 4\n",
        "hi_cut  = 40\n",
        "\n",
        "raw_filt = raw.copy().filter(low_cut, hi_cut)\n",
        "#raw.filter(4,40.,fir_design='firwin')\n",
        "#raw.plot_psd(area_mode='range', tmax=10.0,average=False)\n",
        "rawdata = raw_filt.get_data()\n",
        "print(rawdata.shape)\n",
        "events, event_id = mne.events_from_annotations(raw_filt)\n",
        "print(events.shape[0])\n",
        "allLeftData = []\n",
        "allRightData = []\n",
        "allFootData = []\n",
        "allTongueData = []\n",
        "for i in range(events.shape[0]-1):\n",
        "  if(events[i,2] == 7):\n",
        "    leftData = rawdata[:,events[i,0]+125:events[i,0]+1125] \n",
        "    allLeftData.append(leftData)\n",
        "  if(events[i,2] == 8):\n",
        "    rightData = rawdata[:,events[i,0]+125:events[i,0]+1125]\n",
        "    allRightData.append(rightData)\n",
        "  if(events[i,2] == 9):\n",
        "    footData = rawdata[:,events[i,0]+125:events[i,0]+1125]\n",
        "    allFootData.append(footData)\n",
        "  if(events[i,2] == 10):\n",
        "    tongueData = rawdata[:,events[i,0]+125:events[i,0]+1125]\n",
        "    allTongueData.append(tongueData)\n",
        "print(len(allLeftData))\n",
        "print(len(allRightData))\n",
        "print(len(allFootData))\n",
        "print(len(allTongueData))\n",
        "allLeftData = np.array(allLeftData) # creates an array \n",
        "allRightData = np.array(allRightData)\n",
        "allFootData = np.array(allFootData)\n",
        "allTongueData = np.array(allTongueData)\n",
        "allLeftData = allLeftData[:71,:22,:] #creating a matrix with 71 rows, 22 columns and 600 depth. 600 is the window size \n",
        "allRightData = allRightData[:71,:22,:]\n",
        "allFootData = allFootData[:71,:22,:]\n",
        "allTongueData = allTongueData[:71,:22,:]\n",
        "print(allLeftData.shape)\n",
        "print(allRightData.shape)\n",
        "print(allFootData.shape)\n",
        "print(allTongueData.shape)\n",
        "\n",
        "def standardlizeSig(data):\n",
        "  base = np.mean(data)\n",
        "  std = np.std(data)\n",
        "  standardlized_data = (data-base)/std\n",
        "  del base, std\n",
        "  return standardlized_data\n",
        "# def standardlizeSig(data):\n",
        "#   minft = data.min()\n",
        "#   maxft = data.max()\n",
        "#   standardlized_data= ((data - minft)/(maxft - minft))\n",
        "#   return standardlized_data\n",
        "\n",
        "allLeftDataTF = []\n",
        "allRightDataTF = []\n",
        "allFootDataTF = []\n",
        "allTongueDataTF = []\n",
        "for i in range (allLeftData.shape[0]):\n",
        "  allLeftDataTF.append(standardlizeSig(allLeftData[i,:,:]))\n",
        "  allRightDataTF.append(standardlizeSig(allRightData[i,:,:]))\n",
        "  allFootDataTF.append(standardlizeSig(allFootData[i,:,:]))\n",
        "  allTongueDataTF.append(standardlizeSig(allTongueData[i,:,:]))\n",
        "allLeftDataTF = np.array(allLeftDataTF) # creates an array \n",
        "allRightDataTF = np.array(allRightDataTF)\n",
        "allFootDataTF = np.array(allFootDataTF)\n",
        "allTongueDataTF = np.array(allTongueDataTF)\n",
        "\n",
        "trainleftLabels = [0] * allLeftDataTF.shape[0]\n",
        "trainrightLabels = [1] * allRightDataTF.shape[0]\n",
        "trainfootLabels = [2] * allFootDataTF.shape[0]\n",
        "traintongueLabels = [3] * allTongueDataTF.shape[0]\n",
        "allTrainLabels = trainleftLabels + trainrightLabels + trainfootLabels + traintongueLabels\n",
        "allTrainLabels = np.array(allTrainLabels)\n",
        "allTrainData = np.concatenate((allTongueDataTF, allLeftDataTF, allRightDataTF, allFootDataTF))\n",
        "X_train, X_rem, Y_train, Y_rem = train_test_split(allTrainData, allTrainLabels, test_size=0.4, random_state=42)\n",
        "X_validate,X_test,Y_validate,Y_test  = train_test_split(X_rem, Y_rem, test_size=0.1,random_state=42)\n",
        "print (X_train.shape,X_validate.shape,X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu167aHrXkpb",
        "outputId": "0fb36482-b0f6-4001-ac5b-65f78e204206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(170, 22, 1000) [1 1 1 2 2 1 1 2 3 3 1 3 1 2 0 3 3 1 2 2 3 3 2 0 3 1 2 0 0 0 2 3 2 0 1 2 2\n",
            " 0 3 2 1 0 3 1 2 0 3 1 3 3 1 0 0 2 2 2 2 0 3 3 0 2 0 1 0 2 2 2 3 1 0 1 1 3\n",
            " 3 0 3 0 0 2 2 0 1 3 2 0 3 3 1 0 2 2 0 0 1 3 3 2 2 0 2 2 3 0 1 0 1 0 3 1 0\n",
            " 2 1 2 0 3 0 2 2 3 1 1 1 1 0 1 0 0 0 1 1 0 2 1 3 1 3 3 3 3 0 3 0 0 2 2 2 2\n",
            " 0 0 3 3 0 2 2 3 2 1 2 1 1 3 1 3 0 2 1 1 3 1]\n",
            "(340,) (340, 22, 1000)\n"
          ]
        }
      ],
      "source": [
        "mu=0.0\n",
        "std =0.02 # for %5 Gaussian noise\n",
        "def gaussian_noise(x,mu,std):\n",
        "    noise = np.random.normal(mu, std, size = x.shape)\n",
        "    x_noisy = x + noise\n",
        "    return x_noisy \n",
        "\n",
        "TrainData_temp=[]\n",
        "TrainData_temp_label=[]\n",
        "for i in range(X_train.shape[0]):\n",
        "  #random_trial=np.random.randint(0,X_train.shape[0])\n",
        "  NoisyData=gaussian_noise(X_train[i],mu,std)\n",
        "  TrainData_temp.append(NoisyData)\n",
        "  TrainData_temp_label.append(Y_train[i])\n",
        "\n",
        "\n",
        "TrainData_temp=np.array(TrainData_temp)\n",
        "TrainData_temp_label=np.array(TrainData_temp_label)\n",
        "print(TrainData_temp.shape,TrainData_temp_label)\n",
        "\n",
        "\n",
        "TrainData=np.concatenate((X_train,TrainData_temp))\n",
        "TrainLabel=np.concatenate((Y_train,TrainData_temp_label))\n",
        "print(TrainLabel.shape, TrainData.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nAw10QDzJrc"
      },
      "outputs": [],
      "source": [
        "kernels, chans, samples = 1, 22, TrainData.shape[2]\n",
        "TrainData1      = TrainData.reshape(TrainData.shape[0], chans, samples, kernels)\n",
        "ValidData1  = X_validate.reshape(X_validate.shape[0], chans, samples, kernels)\n",
        "TestData1  = X_test.reshape(X_test.shape[0], chans, samples, kernels)\n",
        "TrainLabel1     = np_utils.to_categorical(TrainLabel)\n",
        "ValidLabel1  = np_utils.to_categorical(Y_validate)\n",
        "TestLabel1  = np_utils.to_categorical(Y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1WvbCi6WVcn"
      },
      "outputs": [],
      "source": [
        "def DeepConvNet(nb_classes, Chans = 64, Samples = 256,\n",
        "                dropoutRate = 0.5, version = '2017',last_layer='Conv'):\n",
        "    \"\"\" Keras implementation of the Deep Convolutional Network as described in\n",
        "    Schirrmeister et. al. (2017), Human Brain Mapping.\n",
        "    \n",
        "    This implementation assumes the input is a 2-second EEG signal sampled at \n",
        "    128Hz, as opposed to signals sampled at 250Hz as described in the original\n",
        "    paper. We also perform temporal convolutions of length (1, 5) as opposed\n",
        "    to (1, 10) due to this sampling rate difference. \n",
        "    \n",
        "    Note that we use the max_norm constraint on all convolutional layers, as \n",
        "    well as the classification layer. We also change the defaults for the\n",
        "    BatchNormalization layer. We used this based on a personal communication \n",
        "    with the original authors.\n",
        "    \n",
        "                      ours        original paper\n",
        "    pool_size        1, 2        1, 3\n",
        "    strides          1, 2        1, 3\n",
        "    conv filters     1, 5        1, 10\n",
        "    \n",
        "    Note that this implementation has not been verified by the original \n",
        "    authors. \n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    if version=='2017':\n",
        "        bias_spatial = False\n",
        "        pool = (1,3)\n",
        "        strid = (1,3)\n",
        "        filters = (1,10)\n",
        "    elif version=='2018':\n",
        "        bias_spatial = True\n",
        "        pool = (1,2)\n",
        "        strid = (1,2)\n",
        "        filters = (1,5)\n",
        "\n",
        "\n",
        "    # start the modelDeepConvNet(\n",
        "    input_main   = Input((Chans, Samples, 1),name='Input')\n",
        "    block1       = Conv2D(25, filters, \n",
        "                                 input_shape=(Chans, Samples, 1),\n",
        "                                 kernel_constraint = max_norm(2., axis=(0,1,2)),name='Conv2D_1')(input_main)\n",
        "    block1       = Conv2D(25, (Chans, 1),\n",
        "                                 kernel_constraint = max_norm(2., axis=(0,1,2)),use_bias=bias_spatial,name='Conv2D_2')(block1) # Bias False en repo\n",
        "    block1       = BatchNormalization(epsilon=1e-05, momentum=0.1,name='BN_1')(block1)\n",
        "    block1       = Activation('elu',name='A_1')(block1)\n",
        "    block1       = MaxPooling2D(pool_size=pool, strides=strid,name='MP_1')(block1)\n",
        "    block1       = Dropout(dropoutRate,name='Dp_1')(block1) \n",
        "  \n",
        "    block2       = Conv2D(50, filters,\n",
        "                                 kernel_constraint = max_norm(2., axis=(0,1,2)),name='Conv2D_3')(block1)\n",
        "    block2       = BatchNormalization(epsilon=1e-05, momentum=0.1,name='BN_2')(block2)\n",
        "    block2       = Activation('elu',name='A_2')(block2)\n",
        "    block2       = MaxPooling2D(pool_size=pool, strides=strid,name='MP_2')(block2)\n",
        "    block2       = Dropout(dropoutRate,name='Dp_2')(block2)\n",
        "    \n",
        "    block3       = Conv2D(100, filters,\n",
        "                                 kernel_constraint = max_norm(2., axis=(0,1,2)),name='Conv2_4')(block2)\n",
        "    block3       = BatchNormalization(epsilon=1e-05, momentum=0.1,name='BN_3')(block3)\n",
        "    block3       = Activation('elu',name='A_3')(block3)\n",
        "    block3       = MaxPooling2D(pool_size=pool, strides=strid,name='MP_3')(block3)\n",
        "    block3       = Dropout(dropoutRate,name='Dp_3')(block3)\n",
        "    \n",
        "    block4       = Conv2D(200, filters,\n",
        "                                 kernel_constraint = max_norm(2., axis=(0,1,2)),name='Conv2d_5')(block3)\n",
        "    block4       = BatchNormalization(epsilon=1e-05, momentum=0.1,name='BN_4')(block4)\n",
        "    block4       = Activation('elu',name='A_4')(block4)\n",
        "    block4       = MaxPooling2D(pool_size=pool, strides=strid,name='MP_4')(block4)\n",
        "    block4       = Dropout(dropoutRate,name='Dp_4')(block4)# igual a repo\n",
        "    \n",
        "\n",
        "    # if version=='2017'or last_layer=='Conv':\n",
        "    #     ConvC        = Conv2D(nb_classes, (1, block4.shape[2]),kernel_constraint = max_norm(0.5, axis=(0,1,2)),name='ouput')(block4)\n",
        "    #     flat          = Flatten(name='F_1')(ConvC)\n",
        "    #     softmax      = Activation('softmax',name='out_activation')(flat)\n",
        "\n",
        "    if version=='2017' or last_layer=='Conv':\n",
        "        flatten      = Flatten(name='F_1')(block4)\n",
        "        dense        = Dense(nb_classes, kernel_constraint = max_norm(0.5),name='output')(flatten)\n",
        "        softmax      = Activation('softmax',name='out_activation')(dense)\n",
        "    \n",
        "    return Model(inputs=input_main, outputs=softmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM7FMUNaXcAY",
        "outputId": "e123cede-c0f2-403f-fbda-931dfd47e0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Input (InputLayer)          [(None, 22, 1000, 1)]     0         \n",
            "                                                                 \n",
            " Conv2D_1 (Conv2D)           (None, 22, 991, 25)       275       \n",
            "                                                                 \n",
            " Conv2D_2 (Conv2D)           (None, 1, 991, 25)        13750     \n",
            "                                                                 \n",
            " BN_1 (BatchNormalization)   (None, 1, 991, 25)        100       \n",
            "                                                                 \n",
            " A_1 (Activation)            (None, 1, 991, 25)        0         \n",
            "                                                                 \n",
            " MP_1 (MaxPooling2D)         (None, 1, 330, 25)        0         \n",
            "                                                                 \n",
            " Dp_1 (Dropout)              (None, 1, 330, 25)        0         \n",
            "                                                                 \n",
            " Conv2D_3 (Conv2D)           (None, 1, 321, 50)        12550     \n",
            "                                                                 \n",
            " BN_2 (BatchNormalization)   (None, 1, 321, 50)        200       \n",
            "                                                                 \n",
            " A_2 (Activation)            (None, 1, 321, 50)        0         \n",
            "                                                                 \n",
            " MP_2 (MaxPooling2D)         (None, 1, 107, 50)        0         \n",
            "                                                                 \n",
            " Dp_2 (Dropout)              (None, 1, 107, 50)        0         \n",
            "                                                                 \n",
            " Conv2_4 (Conv2D)            (None, 1, 98, 100)        50100     \n",
            "                                                                 \n",
            " BN_3 (BatchNormalization)   (None, 1, 98, 100)        400       \n",
            "                                                                 \n",
            " A_3 (Activation)            (None, 1, 98, 100)        0         \n",
            "                                                                 \n",
            " MP_3 (MaxPooling2D)         (None, 1, 32, 100)        0         \n",
            "                                                                 \n",
            " Dp_3 (Dropout)              (None, 1, 32, 100)        0         \n",
            "                                                                 \n",
            " Conv2d_5 (Conv2D)           (None, 1, 23, 200)        200200    \n",
            "                                                                 \n",
            " BN_4 (BatchNormalization)   (None, 1, 23, 200)        800       \n",
            "                                                                 \n",
            " A_4 (Activation)            (None, 1, 23, 200)        0         \n",
            "                                                                 \n",
            " MP_4 (MaxPooling2D)         (None, 1, 7, 200)         0         \n",
            "                                                                 \n",
            " Dp_4 (Dropout)              (None, 1, 7, 200)         0         \n",
            "                                                                 \n",
            " F_1 (Flatten)               (None, 1400)              0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 4)                 5604      \n",
            "                                                                 \n",
            " out_activation (Activation)  (None, 4)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 283,979\n",
            "Trainable params: 283,229\n",
            "Non-trainable params: 750\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=DeepConvNet(nb_classes=4, Chans = 22, Samples = TrainData.shape[2], dropoutRate = 0.5,version = '2017',last_layer='Dense')\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    to_file='model.png',\n",
        "    show_shapes=False,\n",
        "    show_dtype=False,\n",
        "    show_layer_names=True,\n",
        "    rankdir='TB',\n",
        "    expand_nested=False,\n",
        "    dpi=96,\n",
        "    layer_range=None,\n",
        "    show_layer_activations=False\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KBLvIp0plVQ",
        "outputId": "6504f418-3298-48c5-8547-fa65f36dd937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/750\n",
            "6/6 [==============================] - 5s 221ms/step - loss: 1.7924 - accuracy: 0.2588 - val_loss: 1.3267 - val_accuracy: 0.3431\n",
            "Epoch 2/750\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 1.4607 - accuracy: 0.3176 - val_loss: 1.4891 - val_accuracy: 0.2843\n",
            "Epoch 3/750\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 1.4023 - accuracy: 0.3382 - val_loss: 1.5678 - val_accuracy: 0.2843\n",
            "Epoch 4/750\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 1.3347 - accuracy: 0.4618 - val_loss: 2.1384 - val_accuracy: 0.2843\n",
            "Epoch 5/750\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 1.2971 - accuracy: 0.3941 - val_loss: 2.4388 - val_accuracy: 0.2843\n",
            "Epoch 6/750\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 1.1560 - accuracy: 0.4941 - val_loss: 2.9285 - val_accuracy: 0.2843\n",
            "Epoch 7/750\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 1.1240 - accuracy: 0.5000 - val_loss: 3.3620 - val_accuracy: 0.2843\n",
            "Epoch 8/750\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 1.0751 - accuracy: 0.5059 - val_loss: 3.0100 - val_accuracy: 0.2843\n",
            "Epoch 9/750\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 1.0443 - accuracy: 0.5559 - val_loss: 3.4320 - val_accuracy: 0.2843\n",
            "Epoch 10/750\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 1.0013 - accuracy: 0.5382 - val_loss: 2.8887 - val_accuracy: 0.3039\n",
            "Epoch 11/750\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.9695 - accuracy: 0.5559 - val_loss: 3.2518 - val_accuracy: 0.2941\n",
            "Epoch 12/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.9694 - accuracy: 0.5706 - val_loss: 2.2785 - val_accuracy: 0.3431\n",
            "Epoch 13/750\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 0.9348 - accuracy: 0.5794 - val_loss: 2.9231 - val_accuracy: 0.3039\n",
            "Epoch 14/750\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.8984 - accuracy: 0.5941 - val_loss: 2.7133 - val_accuracy: 0.3039\n",
            "Epoch 15/750\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.9464 - accuracy: 0.5824 - val_loss: 3.0059 - val_accuracy: 0.2941\n",
            "Epoch 16/750\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.8924 - accuracy: 0.6000 - val_loss: 2.4241 - val_accuracy: 0.3235\n",
            "Epoch 17/750\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.8824 - accuracy: 0.6000 - val_loss: 2.3695 - val_accuracy: 0.3431\n",
            "Epoch 18/750\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.7884 - accuracy: 0.6441 - val_loss: 1.9071 - val_accuracy: 0.3725\n",
            "Epoch 19/750\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.7621 - accuracy: 0.6853 - val_loss: 2.1004 - val_accuracy: 0.3725\n",
            "Epoch 20/750\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.7886 - accuracy: 0.6588 - val_loss: 1.9792 - val_accuracy: 0.3922\n",
            "Epoch 21/750\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.7543 - accuracy: 0.6853 - val_loss: 1.7390 - val_accuracy: 0.4020\n",
            "Epoch 22/750\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.7238 - accuracy: 0.6735 - val_loss: 1.8805 - val_accuracy: 0.4118\n",
            "Epoch 23/750\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.7118 - accuracy: 0.6941 - val_loss: 1.7045 - val_accuracy: 0.4020\n",
            "Epoch 24/750\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.7221 - accuracy: 0.6941 - val_loss: 1.6698 - val_accuracy: 0.4216\n",
            "Epoch 25/750\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.6753 - accuracy: 0.7382 - val_loss: 1.9175 - val_accuracy: 0.3922\n",
            "Epoch 26/750\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.6272 - accuracy: 0.7500 - val_loss: 1.6394 - val_accuracy: 0.4412\n",
            "Epoch 27/750\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.6244 - accuracy: 0.7676 - val_loss: 1.3881 - val_accuracy: 0.4902\n",
            "Epoch 28/750\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 0.6942 - accuracy: 0.7147 - val_loss: 1.7163 - val_accuracy: 0.4608\n",
            "Epoch 29/750\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.5892 - accuracy: 0.7559 - val_loss: 1.5079 - val_accuracy: 0.5196\n",
            "Epoch 30/750\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.6172 - accuracy: 0.7471 - val_loss: 1.4649 - val_accuracy: 0.5000\n",
            "Epoch 31/750\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.5659 - accuracy: 0.7647 - val_loss: 1.5563 - val_accuracy: 0.4804\n",
            "Epoch 32/750\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.6070 - accuracy: 0.7647 - val_loss: 1.5598 - val_accuracy: 0.4902\n",
            "Epoch 33/750\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.5179 - accuracy: 0.8000 - val_loss: 1.6809 - val_accuracy: 0.4510\n",
            "Epoch 34/750\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.5204 - accuracy: 0.7882 - val_loss: 1.7083 - val_accuracy: 0.4510\n",
            "Epoch 35/750\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.4699 - accuracy: 0.8235 - val_loss: 1.4873 - val_accuracy: 0.5000\n",
            "Epoch 36/750\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.4842 - accuracy: 0.8324 - val_loss: 1.4490 - val_accuracy: 0.5000\n",
            "Epoch 37/750\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.4551 - accuracy: 0.8294 - val_loss: 1.5441 - val_accuracy: 0.4706\n",
            "Epoch 38/750\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 0.4743 - accuracy: 0.8353 - val_loss: 1.5277 - val_accuracy: 0.4706\n",
            "Epoch 39/750\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 0.4233 - accuracy: 0.8176 - val_loss: 1.2915 - val_accuracy: 0.5196\n",
            "Epoch 40/750\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 0.4433 - accuracy: 0.8412 - val_loss: 1.2770 - val_accuracy: 0.5196\n",
            "Epoch 41/750\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.4464 - accuracy: 0.8294 - val_loss: 1.1519 - val_accuracy: 0.5392\n",
            "Epoch 42/750\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.4557 - accuracy: 0.8324 - val_loss: 1.5474 - val_accuracy: 0.5000\n",
            "Epoch 43/750\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.3600 - accuracy: 0.8941 - val_loss: 1.3650 - val_accuracy: 0.5098\n",
            "Epoch 44/750\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 0.3527 - accuracy: 0.8912 - val_loss: 1.6029 - val_accuracy: 0.4706\n",
            "Epoch 45/750\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 0.3659 - accuracy: 0.8824 - val_loss: 1.4869 - val_accuracy: 0.4902\n",
            "Epoch 46/750\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.3739 - accuracy: 0.8647 - val_loss: 1.4168 - val_accuracy: 0.4902\n",
            "Epoch 47/750\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 0.3760 - accuracy: 0.8941 - val_loss: 1.2116 - val_accuracy: 0.5392\n",
            "Epoch 48/750\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.3366 - accuracy: 0.8853 - val_loss: 1.4926 - val_accuracy: 0.5490\n",
            "Epoch 49/750\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.3068 - accuracy: 0.8765 - val_loss: 1.6187 - val_accuracy: 0.4804\n",
            "Epoch 50/750\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.3161 - accuracy: 0.8882 - val_loss: 1.0738 - val_accuracy: 0.5784\n",
            "Epoch 51/750\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 0.2887 - accuracy: 0.9176 - val_loss: 1.2377 - val_accuracy: 0.5686\n",
            "Epoch 52/750\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.2930 - accuracy: 0.8882 - val_loss: 1.2217 - val_accuracy: 0.5588\n",
            "Epoch 53/750\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.2871 - accuracy: 0.9029 - val_loss: 1.2415 - val_accuracy: 0.5686\n",
            "Epoch 54/750\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.2619 - accuracy: 0.9235 - val_loss: 1.3444 - val_accuracy: 0.5686\n",
            "Epoch 55/750\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.2723 - accuracy: 0.9088 - val_loss: 1.2107 - val_accuracy: 0.5588\n",
            "Epoch 56/750\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.2626 - accuracy: 0.9118 - val_loss: 1.2740 - val_accuracy: 0.5686\n",
            "Epoch 57/750\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.2282 - accuracy: 0.9176 - val_loss: 1.1498 - val_accuracy: 0.6176\n",
            "Epoch 58/750\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.2612 - accuracy: 0.9059 - val_loss: 1.3673 - val_accuracy: 0.5588\n",
            "Epoch 59/750\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 0.1903 - accuracy: 0.9441 - val_loss: 1.2155 - val_accuracy: 0.5686\n",
            "Epoch 60/750\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.2301 - accuracy: 0.9294 - val_loss: 1.2390 - val_accuracy: 0.5294\n",
            "Epoch 61/750\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.2252 - accuracy: 0.9382 - val_loss: 1.2998 - val_accuracy: 0.5196\n",
            "Epoch 62/750\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.2284 - accuracy: 0.9235 - val_loss: 1.1872 - val_accuracy: 0.5882\n",
            "Epoch 63/750\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.1928 - accuracy: 0.9559 - val_loss: 0.9981 - val_accuracy: 0.6176\n",
            "Epoch 64/750\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 0.1690 - accuracy: 0.9647 - val_loss: 1.1615 - val_accuracy: 0.5588\n",
            "Epoch 65/750\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.2087 - accuracy: 0.9382 - val_loss: 1.1541 - val_accuracy: 0.6078\n",
            "Epoch 66/750\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 0.1911 - accuracy: 0.9441 - val_loss: 1.2028 - val_accuracy: 0.5980\n",
            "Epoch 67/750\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 0.2310 - accuracy: 0.9088 - val_loss: 1.1110 - val_accuracy: 0.6373\n",
            "Epoch 68/750\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.2249 - accuracy: 0.9265 - val_loss: 1.1963 - val_accuracy: 0.6078\n",
            "Epoch 69/750\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 0.1734 - accuracy: 0.9471 - val_loss: 1.2824 - val_accuracy: 0.5784\n",
            "Epoch 70/750\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.1985 - accuracy: 0.9471 - val_loss: 1.2097 - val_accuracy: 0.6176\n",
            "Epoch 71/750\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.2020 - accuracy: 0.9294 - val_loss: 1.4451 - val_accuracy: 0.5196\n",
            "Epoch 72/750\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.1281 - accuracy: 0.9794 - val_loss: 1.1114 - val_accuracy: 0.6078\n",
            "Epoch 73/750\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 0.1781 - accuracy: 0.9441 - val_loss: 1.1530 - val_accuracy: 0.5784\n",
            "Epoch 74/750\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.1536 - accuracy: 0.9647 - val_loss: 1.0730 - val_accuracy: 0.6373\n",
            "Epoch 75/750\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.1664 - accuracy: 0.9471 - val_loss: 1.0505 - val_accuracy: 0.6667\n",
            "Epoch 76/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.1565 - accuracy: 0.9559 - val_loss: 1.2707 - val_accuracy: 0.6275\n",
            "Epoch 77/750\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.1426 - accuracy: 0.9647 - val_loss: 1.2033 - val_accuracy: 0.6176\n",
            "Epoch 78/750\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 0.1324 - accuracy: 0.9588 - val_loss: 0.9989 - val_accuracy: 0.6863\n",
            "Epoch 79/750\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.1396 - accuracy: 0.9618 - val_loss: 1.3382 - val_accuracy: 0.5784\n",
            "Epoch 80/750\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.1566 - accuracy: 0.9559 - val_loss: 1.4451 - val_accuracy: 0.5588\n",
            "Epoch 81/750\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.1308 - accuracy: 0.9647 - val_loss: 1.1246 - val_accuracy: 0.6176\n",
            "Epoch 82/750\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 0.1060 - accuracy: 0.9912 - val_loss: 0.9607 - val_accuracy: 0.6471\n",
            "Epoch 83/750\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.1376 - accuracy: 0.9735 - val_loss: 1.0645 - val_accuracy: 0.6373\n",
            "Epoch 84/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.1411 - accuracy: 0.9559 - val_loss: 1.1373 - val_accuracy: 0.6373\n",
            "Epoch 85/750\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.1069 - accuracy: 0.9853 - val_loss: 1.1599 - val_accuracy: 0.6373\n",
            "Epoch 86/750\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.1281 - accuracy: 0.9676 - val_loss: 1.0470 - val_accuracy: 0.6569\n",
            "Epoch 87/750\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.1304 - accuracy: 0.9618 - val_loss: 1.1062 - val_accuracy: 0.6569\n",
            "Epoch 88/750\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.1268 - accuracy: 0.9706 - val_loss: 1.1922 - val_accuracy: 0.6471\n",
            "Epoch 89/750\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.1222 - accuracy: 0.9735 - val_loss: 1.0963 - val_accuracy: 0.6471\n",
            "Epoch 90/750\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 0.0961 - accuracy: 0.9765 - val_loss: 1.1785 - val_accuracy: 0.6275\n",
            "Epoch 91/750\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 0.0943 - accuracy: 0.9794 - val_loss: 1.2777 - val_accuracy: 0.5980\n",
            "Epoch 92/750\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.1202 - accuracy: 0.9706 - val_loss: 0.9667 - val_accuracy: 0.6863\n",
            "Epoch 93/750\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.0804 - accuracy: 0.9941 - val_loss: 1.3689 - val_accuracy: 0.5980\n",
            "Epoch 94/750\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 0.1128 - accuracy: 0.9676 - val_loss: 0.8839 - val_accuracy: 0.6961\n",
            "Epoch 95/750\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.0945 - accuracy: 0.9706 - val_loss: 1.1252 - val_accuracy: 0.6373\n",
            "Epoch 96/750\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 0.1007 - accuracy: 0.9765 - val_loss: 1.3122 - val_accuracy: 0.6078\n",
            "Epoch 97/750\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0900 - accuracy: 0.9765 - val_loss: 1.0519 - val_accuracy: 0.6471\n",
            "Epoch 98/750\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 0.0862 - accuracy: 0.9735 - val_loss: 1.3871 - val_accuracy: 0.5980\n",
            "Epoch 99/750\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0979 - accuracy: 0.9735 - val_loss: 1.0405 - val_accuracy: 0.6569\n",
            "Epoch 100/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0721 - accuracy: 0.9941 - val_loss: 1.0572 - val_accuracy: 0.6569\n",
            "Epoch 101/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.1108 - accuracy: 0.9735 - val_loss: 1.0254 - val_accuracy: 0.6765\n",
            "Epoch 102/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0996 - accuracy: 0.9735 - val_loss: 1.3650 - val_accuracy: 0.5980\n",
            "Epoch 103/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0935 - accuracy: 0.9824 - val_loss: 1.1754 - val_accuracy: 0.6471\n",
            "Epoch 104/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1037 - accuracy: 0.9735 - val_loss: 1.1335 - val_accuracy: 0.6765\n",
            "Epoch 105/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0982 - accuracy: 0.9706 - val_loss: 0.9953 - val_accuracy: 0.6765\n",
            "Epoch 106/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0774 - accuracy: 0.9882 - val_loss: 1.2768 - val_accuracy: 0.6275\n",
            "Epoch 107/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.1011 - accuracy: 0.9794 - val_loss: 0.9927 - val_accuracy: 0.6569\n",
            "Epoch 108/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0703 - accuracy: 0.9941 - val_loss: 0.9765 - val_accuracy: 0.6765\n",
            "Epoch 109/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0952 - accuracy: 0.9794 - val_loss: 1.3120 - val_accuracy: 0.6373\n",
            "Epoch 110/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0684 - accuracy: 0.9941 - val_loss: 1.2825 - val_accuracy: 0.6275\n",
            "Epoch 111/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0735 - accuracy: 0.9824 - val_loss: 1.1562 - val_accuracy: 0.6373\n",
            "Epoch 112/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0890 - accuracy: 0.9706 - val_loss: 1.0259 - val_accuracy: 0.6863\n",
            "Epoch 113/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0601 - accuracy: 0.9941 - val_loss: 1.0613 - val_accuracy: 0.6373\n",
            "Epoch 114/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0684 - accuracy: 0.9853 - val_loss: 1.2068 - val_accuracy: 0.6275\n",
            "Epoch 115/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0736 - accuracy: 0.9912 - val_loss: 1.1185 - val_accuracy: 0.6373\n",
            "Epoch 116/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0643 - accuracy: 0.9882 - val_loss: 1.1487 - val_accuracy: 0.6373\n",
            "Epoch 117/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0791 - accuracy: 0.9824 - val_loss: 1.1493 - val_accuracy: 0.6373\n",
            "Epoch 118/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0770 - accuracy: 0.9912 - val_loss: 0.9071 - val_accuracy: 0.7255\n",
            "Epoch 119/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0740 - accuracy: 0.9824 - val_loss: 1.3302 - val_accuracy: 0.6373\n",
            "Epoch 120/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0666 - accuracy: 0.9853 - val_loss: 1.3142 - val_accuracy: 0.6373\n",
            "Epoch 121/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0829 - accuracy: 0.9765 - val_loss: 1.1531 - val_accuracy: 0.6471\n",
            "Epoch 122/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0624 - accuracy: 0.9882 - val_loss: 0.9853 - val_accuracy: 0.6569\n",
            "Epoch 123/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0849 - accuracy: 0.9824 - val_loss: 1.0286 - val_accuracy: 0.6765\n",
            "Epoch 124/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0531 - accuracy: 0.9941 - val_loss: 1.0179 - val_accuracy: 0.6863\n",
            "Epoch 125/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0644 - accuracy: 0.9853 - val_loss: 1.2205 - val_accuracy: 0.6275\n",
            "Epoch 126/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0803 - accuracy: 0.9882 - val_loss: 1.1760 - val_accuracy: 0.6275\n",
            "Epoch 127/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0685 - accuracy: 0.9912 - val_loss: 1.2763 - val_accuracy: 0.6373\n",
            "Epoch 128/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0974 - accuracy: 0.9765 - val_loss: 1.2190 - val_accuracy: 0.6569\n",
            "Epoch 129/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0614 - accuracy: 0.9824 - val_loss: 1.1721 - val_accuracy: 0.6569\n",
            "Epoch 130/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0462 - accuracy: 0.9912 - val_loss: 1.0934 - val_accuracy: 0.6765\n",
            "Epoch 131/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0579 - accuracy: 0.9794 - val_loss: 1.2995 - val_accuracy: 0.6373\n",
            "Epoch 132/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0449 - accuracy: 0.9912 - val_loss: 1.2584 - val_accuracy: 0.6373\n",
            "Epoch 133/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0478 - accuracy: 0.9912 - val_loss: 1.1194 - val_accuracy: 0.6471\n",
            "Epoch 134/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0745 - accuracy: 0.9882 - val_loss: 0.8689 - val_accuracy: 0.7059\n",
            "Epoch 135/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0567 - accuracy: 0.9882 - val_loss: 1.2426 - val_accuracy: 0.6275\n",
            "Epoch 136/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0573 - accuracy: 0.9853 - val_loss: 1.2414 - val_accuracy: 0.6176\n",
            "Epoch 137/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0464 - accuracy: 0.9971 - val_loss: 1.0361 - val_accuracy: 0.6667\n",
            "Epoch 138/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0384 - accuracy: 0.9971 - val_loss: 1.1583 - val_accuracy: 0.6471\n",
            "Epoch 139/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0670 - accuracy: 0.9824 - val_loss: 0.9672 - val_accuracy: 0.6765\n",
            "Epoch 140/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0445 - accuracy: 0.9941 - val_loss: 0.9795 - val_accuracy: 0.6765\n",
            "Epoch 141/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0509 - accuracy: 0.9882 - val_loss: 1.0690 - val_accuracy: 0.6863\n",
            "Epoch 142/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0514 - accuracy: 0.9912 - val_loss: 1.0773 - val_accuracy: 0.6765\n",
            "Epoch 143/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0468 - accuracy: 0.9941 - val_loss: 1.0251 - val_accuracy: 0.6667\n",
            "Epoch 144/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0546 - accuracy: 0.9941 - val_loss: 1.2143 - val_accuracy: 0.6471\n",
            "Epoch 145/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0448 - accuracy: 0.9912 - val_loss: 1.1516 - val_accuracy: 0.6471\n",
            "Epoch 146/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0593 - accuracy: 0.9824 - val_loss: 0.9382 - val_accuracy: 0.6863\n",
            "Epoch 147/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0576 - accuracy: 0.9824 - val_loss: 0.9778 - val_accuracy: 0.6961\n",
            "Epoch 148/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0419 - accuracy: 0.9941 - val_loss: 1.0545 - val_accuracy: 0.6569\n",
            "Epoch 149/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0520 - accuracy: 0.9912 - val_loss: 1.0175 - val_accuracy: 0.6569\n",
            "Epoch 150/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0524 - accuracy: 0.9824 - val_loss: 0.8281 - val_accuracy: 0.7353\n",
            "Epoch 151/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0466 - accuracy: 0.9912 - val_loss: 1.1435 - val_accuracy: 0.6373\n",
            "Epoch 152/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0463 - accuracy: 0.9912 - val_loss: 1.1071 - val_accuracy: 0.6569\n",
            "Epoch 153/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0437 - accuracy: 0.9882 - val_loss: 1.1311 - val_accuracy: 0.6471\n",
            "Epoch 154/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0435 - accuracy: 0.9971 - val_loss: 1.0569 - val_accuracy: 0.6667\n",
            "Epoch 155/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0423 - accuracy: 0.9912 - val_loss: 1.1876 - val_accuracy: 0.6667\n",
            "Epoch 156/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0439 - accuracy: 0.9941 - val_loss: 1.2926 - val_accuracy: 0.6373\n",
            "Epoch 157/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0345 - accuracy: 0.9971 - val_loss: 0.9103 - val_accuracy: 0.6961\n",
            "Epoch 158/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0410 - accuracy: 0.9971 - val_loss: 0.9630 - val_accuracy: 0.6765\n",
            "Epoch 159/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0461 - accuracy: 0.9941 - val_loss: 1.5519 - val_accuracy: 0.5980\n",
            "Epoch 160/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0356 - accuracy: 0.9971 - val_loss: 0.9862 - val_accuracy: 0.6863\n",
            "Epoch 161/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0347 - accuracy: 0.9971 - val_loss: 0.9218 - val_accuracy: 0.6961\n",
            "Epoch 162/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0353 - accuracy: 0.9971 - val_loss: 1.2346 - val_accuracy: 0.6471\n",
            "Epoch 163/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0328 - accuracy: 0.9941 - val_loss: 0.9725 - val_accuracy: 0.6961\n",
            "Epoch 164/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0363 - accuracy: 0.9971 - val_loss: 1.1000 - val_accuracy: 0.6765\n",
            "Epoch 165/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0396 - accuracy: 0.9941 - val_loss: 0.8862 - val_accuracy: 0.7255\n",
            "Epoch 166/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0413 - accuracy: 0.9971 - val_loss: 1.0927 - val_accuracy: 0.6863\n",
            "Epoch 167/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0390 - accuracy: 0.9971 - val_loss: 1.1640 - val_accuracy: 0.6765\n",
            "Epoch 168/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.9573 - val_accuracy: 0.6863\n",
            "Epoch 169/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0396 - accuracy: 0.9912 - val_loss: 1.0651 - val_accuracy: 0.6471\n",
            "Epoch 170/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0483 - accuracy: 0.9853 - val_loss: 1.2329 - val_accuracy: 0.6373\n",
            "Epoch 171/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0327 - accuracy: 0.9971 - val_loss: 1.0037 - val_accuracy: 0.6765\n",
            "Epoch 172/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0309 - accuracy: 0.9971 - val_loss: 1.0364 - val_accuracy: 0.6961\n",
            "Epoch 173/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0349 - accuracy: 1.0000 - val_loss: 0.9627 - val_accuracy: 0.6961\n",
            "Epoch 174/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0367 - accuracy: 0.9971 - val_loss: 1.0696 - val_accuracy: 0.6765\n",
            "Epoch 175/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0465 - accuracy: 0.9882 - val_loss: 1.1350 - val_accuracy: 0.6667\n",
            "Epoch 176/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0415 - accuracy: 0.9941 - val_loss: 1.0246 - val_accuracy: 0.6863\n",
            "Epoch 177/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0522 - accuracy: 0.9853 - val_loss: 0.9267 - val_accuracy: 0.6961\n",
            "Epoch 178/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.3291 - val_accuracy: 0.6373\n",
            "Epoch 179/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0404 - accuracy: 0.9971 - val_loss: 1.3451 - val_accuracy: 0.6078\n",
            "Epoch 180/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.9340 - val_accuracy: 0.7451\n",
            "Epoch 181/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0385 - accuracy: 0.9971 - val_loss: 0.9140 - val_accuracy: 0.7353\n",
            "Epoch 182/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0379 - accuracy: 0.9971 - val_loss: 1.3732 - val_accuracy: 0.6373\n",
            "Epoch 183/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0651 - accuracy: 0.9882 - val_loss: 0.9310 - val_accuracy: 0.7157\n",
            "Epoch 184/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0412 - accuracy: 0.9971 - val_loss: 1.1320 - val_accuracy: 0.6667\n",
            "Epoch 185/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0366 - accuracy: 0.9971 - val_loss: 1.1584 - val_accuracy: 0.6471\n",
            "Epoch 186/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0299 - accuracy: 0.9971 - val_loss: 1.0996 - val_accuracy: 0.6373\n",
            "Epoch 187/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 1.1651 - val_accuracy: 0.6471\n",
            "Epoch 188/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0333 - accuracy: 0.9912 - val_loss: 1.2336 - val_accuracy: 0.6275\n",
            "Epoch 189/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0329 - accuracy: 0.9971 - val_loss: 0.9853 - val_accuracy: 0.6863\n",
            "Epoch 190/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0371 - accuracy: 0.9941 - val_loss: 1.2282 - val_accuracy: 0.6569\n",
            "Epoch 191/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0326 - accuracy: 0.9941 - val_loss: 1.0191 - val_accuracy: 0.6961\n",
            "Epoch 192/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0299 - accuracy: 0.9941 - val_loss: 1.1439 - val_accuracy: 0.6863\n",
            "Epoch 193/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0351 - accuracy: 0.9941 - val_loss: 0.9663 - val_accuracy: 0.6667\n",
            "Epoch 194/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.8882 - val_accuracy: 0.7157\n",
            "Epoch 195/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0331 - accuracy: 0.9941 - val_loss: 1.3024 - val_accuracy: 0.6471\n",
            "Epoch 196/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0302 - accuracy: 0.9941 - val_loss: 1.2557 - val_accuracy: 0.6373\n",
            "Epoch 197/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0308 - accuracy: 0.9912 - val_loss: 1.1324 - val_accuracy: 0.7059\n",
            "Epoch 198/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 1.1852 - val_accuracy: 0.6471\n",
            "Epoch 199/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0224 - accuracy: 0.9971 - val_loss: 1.1814 - val_accuracy: 0.6471\n",
            "Epoch 200/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0333 - accuracy: 0.9941 - val_loss: 1.1186 - val_accuracy: 0.6471\n",
            "Epoch 201/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0393 - accuracy: 0.9941 - val_loss: 1.0874 - val_accuracy: 0.6667\n",
            "Epoch 202/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0323 - accuracy: 0.9941 - val_loss: 1.1394 - val_accuracy: 0.6667\n",
            "Epoch 203/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 1.2074 - val_accuracy: 0.6275\n",
            "Epoch 204/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.9716 - val_accuracy: 0.6863\n",
            "Epoch 205/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.0820 - val_accuracy: 0.6961\n",
            "Epoch 206/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0246 - accuracy: 0.9971 - val_loss: 0.9020 - val_accuracy: 0.7451\n",
            "Epoch 207/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0339 - accuracy: 0.9912 - val_loss: 1.2362 - val_accuracy: 0.6373\n",
            "Epoch 208/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0261 - accuracy: 0.9971 - val_loss: 1.0687 - val_accuracy: 0.6765\n",
            "Epoch 209/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0259 - accuracy: 0.9971 - val_loss: 0.9844 - val_accuracy: 0.7059\n",
            "Epoch 210/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0346 - accuracy: 0.9941 - val_loss: 1.0387 - val_accuracy: 0.6961\n",
            "Epoch 211/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0246 - accuracy: 0.9971 - val_loss: 1.1090 - val_accuracy: 0.6765\n",
            "Epoch 212/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0340 - accuracy: 0.9912 - val_loss: 1.1018 - val_accuracy: 0.6765\n",
            "Epoch 213/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0366 - accuracy: 0.9941 - val_loss: 1.0216 - val_accuracy: 0.7157\n",
            "Epoch 214/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 1.0583 - val_accuracy: 0.6667\n",
            "Epoch 215/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0287 - accuracy: 0.9941 - val_loss: 1.2537 - val_accuracy: 0.6471\n",
            "Epoch 216/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.1439 - val_accuracy: 0.6667\n",
            "Epoch 217/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.0314 - val_accuracy: 0.6961\n",
            "Epoch 218/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0199 - accuracy: 0.9971 - val_loss: 1.1009 - val_accuracy: 0.6569\n",
            "Epoch 219/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0265 - accuracy: 0.9941 - val_loss: 1.0938 - val_accuracy: 0.6863\n",
            "Epoch 220/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0341 - accuracy: 0.9912 - val_loss: 0.8779 - val_accuracy: 0.7059\n",
            "Epoch 221/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.0681 - val_accuracy: 0.6863\n",
            "Epoch 222/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0271 - accuracy: 0.9971 - val_loss: 0.9786 - val_accuracy: 0.6667\n",
            "Epoch 223/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.1313 - val_accuracy: 0.6667\n",
            "Epoch 224/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0247 - accuracy: 0.9941 - val_loss: 0.9930 - val_accuracy: 0.6863\n",
            "Epoch 225/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0221 - accuracy: 0.9971 - val_loss: 1.0904 - val_accuracy: 0.6471\n",
            "Epoch 226/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0209 - accuracy: 0.9971 - val_loss: 1.2181 - val_accuracy: 0.6667\n",
            "Epoch 227/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 1.2457 - val_accuracy: 0.6471\n",
            "Epoch 228/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0210 - accuracy: 0.9912 - val_loss: 1.1335 - val_accuracy: 0.6667\n",
            "Epoch 229/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.2823 - val_accuracy: 0.6569\n",
            "Epoch 230/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0239 - accuracy: 0.9941 - val_loss: 1.0530 - val_accuracy: 0.6961\n",
            "Epoch 231/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0227 - accuracy: 0.9971 - val_loss: 0.8575 - val_accuracy: 0.7255\n",
            "Epoch 232/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0193 - accuracy: 0.9971 - val_loss: 1.5750 - val_accuracy: 0.6176\n",
            "Epoch 233/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0282 - accuracy: 0.9941 - val_loss: 1.0677 - val_accuracy: 0.6863\n",
            "Epoch 234/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.0279 - val_accuracy: 0.6961\n",
            "Epoch 235/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.0743 - val_accuracy: 0.6961\n",
            "Epoch 236/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0225 - accuracy: 0.9971 - val_loss: 0.9580 - val_accuracy: 0.7059\n",
            "Epoch 237/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.1461 - val_accuracy: 0.6765\n",
            "Epoch 238/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.0992 - val_accuracy: 0.6863\n",
            "Epoch 239/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.9658 - val_accuracy: 0.6961\n",
            "Epoch 240/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.2322 - val_accuracy: 0.6275\n",
            "Epoch 241/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.1891 - val_accuracy: 0.6667\n",
            "Epoch 242/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0200 - accuracy: 0.9971 - val_loss: 0.8995 - val_accuracy: 0.7059\n",
            "Epoch 243/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.0696 - val_accuracy: 0.7059\n",
            "Epoch 244/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0248 - accuracy: 0.9971 - val_loss: 1.0859 - val_accuracy: 0.6863\n",
            "Epoch 245/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.3465 - val_accuracy: 0.6373\n",
            "Epoch 246/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.9429 - val_accuracy: 0.7059\n",
            "Epoch 247/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0178 - accuracy: 0.9971 - val_loss: 1.0429 - val_accuracy: 0.6667\n",
            "Epoch 248/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.5565 - val_accuracy: 0.5980\n",
            "Epoch 249/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0210 - accuracy: 0.9971 - val_loss: 1.0297 - val_accuracy: 0.6863\n",
            "Epoch 250/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0218 - accuracy: 0.9971 - val_loss: 1.0917 - val_accuracy: 0.6863\n",
            "Epoch 251/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.8446 - val_accuracy: 0.7451\n",
            "Epoch 252/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.0968 - val_accuracy: 0.6765\n",
            "Epoch 253/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.1576 - val_accuracy: 0.6765\n",
            "Epoch 254/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1040 - val_accuracy: 0.7059\n",
            "Epoch 255/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 1.2663 - val_accuracy: 0.6471\n",
            "Epoch 256/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0178 - accuracy: 0.9971 - val_loss: 1.3087 - val_accuracy: 0.6275\n",
            "Epoch 257/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.9986 - val_accuracy: 0.6863\n",
            "Epoch 258/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0222 - accuracy: 0.9941 - val_loss: 0.9896 - val_accuracy: 0.6765\n",
            "Epoch 259/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 1.0347 - val_accuracy: 0.6863\n",
            "Epoch 260/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0271 - accuracy: 0.9912 - val_loss: 0.9270 - val_accuracy: 0.7059\n",
            "Epoch 261/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.0524 - val_accuracy: 0.6863\n",
            "Epoch 262/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0238 - accuracy: 0.9912 - val_loss: 1.0643 - val_accuracy: 0.6863\n",
            "Epoch 263/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.2402 - val_accuracy: 0.6863\n",
            "Epoch 264/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0201 - accuracy: 0.9971 - val_loss: 0.8887 - val_accuracy: 0.7255\n",
            "Epoch 265/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0166 - accuracy: 0.9971 - val_loss: 1.1910 - val_accuracy: 0.6667\n",
            "Epoch 266/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.3311 - val_accuracy: 0.6373\n",
            "Epoch 267/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.2056 - val_accuracy: 0.6471\n",
            "Epoch 268/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0319 - accuracy: 0.9882 - val_loss: 1.5079 - val_accuracy: 0.5882\n",
            "Epoch 269/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0263 - accuracy: 0.9941 - val_loss: 1.3246 - val_accuracy: 0.6471\n",
            "Epoch 270/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.0550 - val_accuracy: 0.6961\n",
            "Epoch 271/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.0071 - val_accuracy: 0.6961\n",
            "Epoch 272/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 1.2871 - val_accuracy: 0.6373\n",
            "Epoch 273/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 1.4608 - val_accuracy: 0.6078\n",
            "Epoch 274/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.8538 - val_accuracy: 0.6961\n",
            "Epoch 275/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0219 - accuracy: 0.9941 - val_loss: 0.9973 - val_accuracy: 0.6765\n",
            "Epoch 276/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.0711 - val_accuracy: 0.6765\n",
            "Epoch 277/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.1774 - val_accuracy: 0.6373\n",
            "Epoch 278/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0212 - accuracy: 0.9971 - val_loss: 0.9925 - val_accuracy: 0.6471\n",
            "Epoch 279/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.9861 - val_accuracy: 0.6667\n",
            "Epoch 280/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 0.9816 - val_accuracy: 0.6471\n",
            "Epoch 281/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.8792 - val_accuracy: 0.6863\n",
            "Epoch 282/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.0734 - val_accuracy: 0.6569\n",
            "Epoch 283/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 1.0052 - val_accuracy: 0.6961\n",
            "Epoch 284/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.9824 - val_accuracy: 0.7059\n",
            "Epoch 285/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.9577 - val_accuracy: 0.7157\n",
            "Epoch 286/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.9434 - val_accuracy: 0.7157\n",
            "Epoch 287/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0232 - accuracy: 0.9941 - val_loss: 1.1661 - val_accuracy: 0.6667\n",
            "Epoch 288/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.9600 - val_accuracy: 0.6961\n",
            "Epoch 289/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0203 - accuracy: 0.9941 - val_loss: 1.0401 - val_accuracy: 0.6765\n",
            "Epoch 290/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0209 - accuracy: 0.9971 - val_loss: 0.9596 - val_accuracy: 0.6863\n",
            "Epoch 291/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.1732 - val_accuracy: 0.6863\n",
            "Epoch 292/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.0870 - val_accuracy: 0.6667\n",
            "Epoch 293/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 1.3684 - val_accuracy: 0.6275\n",
            "Epoch 294/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0143 - accuracy: 0.9971 - val_loss: 1.1694 - val_accuracy: 0.6765\n",
            "Epoch 295/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.9424 - val_accuracy: 0.7157\n",
            "Epoch 296/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0157 - accuracy: 0.9971 - val_loss: 1.0043 - val_accuracy: 0.6863\n",
            "Epoch 297/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.9114 - val_accuracy: 0.6667\n",
            "Epoch 298/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.2383 - val_accuracy: 0.6863\n",
            "Epoch 299/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0127 - accuracy: 0.9971 - val_loss: 0.8557 - val_accuracy: 0.7451\n",
            "Epoch 300/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0161 - accuracy: 0.9941 - val_loss: 1.0228 - val_accuracy: 0.7157\n",
            "Epoch 301/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.2887 - val_accuracy: 0.6275\n",
            "Epoch 302/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.9844 - val_accuracy: 0.6863\n",
            "Epoch 303/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0150 - accuracy: 0.9971 - val_loss: 1.3220 - val_accuracy: 0.6471\n",
            "Epoch 304/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0156 - accuracy: 0.9971 - val_loss: 1.1312 - val_accuracy: 0.6765\n",
            "Epoch 305/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.1288 - val_accuracy: 0.6961\n",
            "Epoch 306/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0161 - accuracy: 0.9971 - val_loss: 1.2463 - val_accuracy: 0.6863\n",
            "Epoch 307/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.2064 - val_accuracy: 0.6667\n",
            "Epoch 308/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.2160 - val_accuracy: 0.6863\n",
            "Epoch 309/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.2145 - val_accuracy: 0.6863\n",
            "Epoch 310/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.2565 - val_accuracy: 0.6667\n",
            "Epoch 311/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.9020 - val_accuracy: 0.7157\n",
            "Epoch 312/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.9254 - val_accuracy: 0.7059\n",
            "Epoch 313/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.2435 - val_accuracy: 0.6569\n",
            "Epoch 314/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.9906 - val_accuracy: 0.7157\n",
            "Epoch 315/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.1332 - val_accuracy: 0.6765\n",
            "Epoch 316/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.0598 - val_accuracy: 0.6961\n",
            "Epoch 317/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.0284 - val_accuracy: 0.6863\n",
            "Epoch 318/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.9746 - val_accuracy: 0.6961\n",
            "Epoch 319/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.0328 - val_accuracy: 0.6961\n",
            "Epoch 320/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.2769 - val_accuracy: 0.6569\n",
            "Epoch 321/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.1016 - val_accuracy: 0.6961\n",
            "Epoch 322/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0163 - accuracy: 0.9941 - val_loss: 1.1037 - val_accuracy: 0.6863\n",
            "Epoch 323/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.0237 - val_accuracy: 0.6863\n",
            "Epoch 324/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.9350 - val_accuracy: 0.6765\n",
            "Epoch 325/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.8891 - val_accuracy: 0.7059\n",
            "Epoch 326/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0160 - accuracy: 0.9971 - val_loss: 0.8921 - val_accuracy: 0.7353\n",
            "Epoch 327/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.9252 - val_accuracy: 0.7255\n",
            "Epoch 328/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.2377 - val_accuracy: 0.6667\n",
            "Epoch 329/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.9465 - val_accuracy: 0.7157\n",
            "Epoch 330/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1866 - val_accuracy: 0.6863\n",
            "Epoch 331/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.0923 - val_accuracy: 0.6667\n",
            "Epoch 332/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.1153 - val_accuracy: 0.6765\n",
            "Epoch 333/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0133 - accuracy: 0.9971 - val_loss: 1.0109 - val_accuracy: 0.6961\n",
            "Epoch 334/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.0671 - val_accuracy: 0.6765\n",
            "Epoch 335/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 1.0291 - val_accuracy: 0.6863\n",
            "Epoch 336/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0144 - accuracy: 0.9971 - val_loss: 0.9472 - val_accuracy: 0.7059\n",
            "Epoch 337/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0169 - accuracy: 0.9971 - val_loss: 0.8165 - val_accuracy: 0.7451\n",
            "Epoch 338/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0248 - accuracy: 0.9941 - val_loss: 1.0143 - val_accuracy: 0.6765\n",
            "Epoch 339/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0159 - accuracy: 0.9971 - val_loss: 0.9221 - val_accuracy: 0.6863\n",
            "Epoch 340/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.1012 - val_accuracy: 0.6863\n",
            "Epoch 341/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.0442 - val_accuracy: 0.7059\n",
            "Epoch 342/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.0941 - val_accuracy: 0.6863\n",
            "Epoch 343/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.9192 - val_accuracy: 0.7255\n",
            "Epoch 344/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 1.0701 - val_accuracy: 0.6961\n",
            "Epoch 345/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.0515 - val_accuracy: 0.7059\n",
            "Epoch 346/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9980 - val_accuracy: 0.7059\n",
            "Epoch 347/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.1548 - val_accuracy: 0.6961\n",
            "Epoch 348/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.9589 - val_accuracy: 0.7157\n",
            "Epoch 349/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0169 - accuracy: 0.9912 - val_loss: 1.1729 - val_accuracy: 0.6765\n",
            "Epoch 350/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 0.9814 - val_accuracy: 0.7059\n",
            "Epoch 351/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.0666 - val_accuracy: 0.6961\n",
            "Epoch 352/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.2177 - val_accuracy: 0.6863\n",
            "Epoch 353/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.2093 - val_accuracy: 0.6765\n",
            "Epoch 354/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.4061 - val_accuracy: 0.6275\n",
            "Epoch 355/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.1588 - val_accuracy: 0.6961\n",
            "Epoch 356/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.1649 - val_accuracy: 0.6961\n",
            "Epoch 357/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.1091 - val_accuracy: 0.7157\n",
            "Epoch 358/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.7353\n",
            "Epoch 359/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0106 - accuracy: 0.9941 - val_loss: 0.8917 - val_accuracy: 0.7353\n",
            "Epoch 360/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.0412 - val_accuracy: 0.6863\n",
            "Epoch 361/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.0337 - val_accuracy: 0.7451\n",
            "Epoch 362/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 1.0990 - val_accuracy: 0.7059\n",
            "Epoch 363/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.9589 - val_accuracy: 0.7255\n",
            "Epoch 364/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.8715 - val_accuracy: 0.7255\n",
            "Epoch 365/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.9869 - val_accuracy: 0.7059\n",
            "Epoch 366/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 1.3723 - val_accuracy: 0.6373\n",
            "Epoch 367/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.9879 - val_accuracy: 0.7451\n",
            "Epoch 368/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.2190 - val_accuracy: 0.6961\n",
            "Epoch 369/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 1.3299 - val_accuracy: 0.6569\n",
            "Epoch 370/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.0186 - val_accuracy: 0.6765\n",
            "Epoch 371/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.0214 - val_accuracy: 0.6961\n",
            "Epoch 372/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.1030 - val_accuracy: 0.6961\n",
            "Epoch 373/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.0441 - val_accuracy: 0.7059\n",
            "Epoch 374/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.1147 - val_accuracy: 0.7157\n",
            "Epoch 375/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 1.1138 - val_accuracy: 0.6863\n",
            "Epoch 376/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.1773 - val_accuracy: 0.6765\n",
            "Epoch 377/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.9957 - val_accuracy: 0.7353\n",
            "Epoch 378/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.0993 - val_accuracy: 0.6961\n",
            "Epoch 379/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0161 - accuracy: 0.9941 - val_loss: 0.9584 - val_accuracy: 0.7157\n",
            "Epoch 380/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.1338 - val_accuracy: 0.6765\n",
            "Epoch 381/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.8866 - val_accuracy: 0.7549\n",
            "Epoch 382/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.8458 - val_accuracy: 0.7353\n",
            "Epoch 383/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.9092 - val_accuracy: 0.7353\n",
            "Epoch 384/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 1.2831 - val_accuracy: 0.6471\n",
            "Epoch 385/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.0225 - val_accuracy: 0.6863\n",
            "Epoch 386/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.0504 - val_accuracy: 0.6961\n",
            "Epoch 387/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.9896 - val_accuracy: 0.6961\n",
            "Epoch 388/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.8537 - val_accuracy: 0.7157\n",
            "Epoch 389/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0118 - accuracy: 0.9971 - val_loss: 0.9468 - val_accuracy: 0.6961\n",
            "Epoch 390/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.9764 - val_accuracy: 0.7059\n",
            "Epoch 391/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.8397 - val_accuracy: 0.7647\n",
            "Epoch 392/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8141 - val_accuracy: 0.7451\n",
            "Epoch 393/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.9832 - val_accuracy: 0.7059\n",
            "Epoch 394/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0149 - accuracy: 0.9971 - val_loss: 1.3251 - val_accuracy: 0.6471\n",
            "Epoch 395/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 1.0344 - val_accuracy: 0.6961\n",
            "Epoch 396/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.8971 - val_accuracy: 0.7549\n",
            "Epoch 397/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.8736 - val_accuracy: 0.7353\n",
            "Epoch 398/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.9852 - val_accuracy: 0.7059\n",
            "Epoch 399/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.2351 - val_accuracy: 0.6863\n",
            "Epoch 400/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.9452 - val_accuracy: 0.7157\n",
            "Epoch 401/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.1794 - val_accuracy: 0.6765\n",
            "Epoch 402/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.1651 - val_accuracy: 0.6667\n",
            "Epoch 403/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.2985 - val_accuracy: 0.6471\n",
            "Epoch 404/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.9723 - val_accuracy: 0.6765\n",
            "Epoch 405/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.9130 - val_accuracy: 0.7353\n",
            "Epoch 406/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.1022 - val_accuracy: 0.6863\n",
            "Epoch 407/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.9649 - val_accuracy: 0.6961\n",
            "Epoch 408/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.1926 - val_accuracy: 0.6471\n",
            "Epoch 409/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.0455 - val_accuracy: 0.6765\n",
            "Epoch 410/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.0909 - val_accuracy: 0.6863\n",
            "Epoch 411/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.0432 - val_accuracy: 0.7059\n",
            "Epoch 412/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 1.2644 - val_accuracy: 0.6667\n",
            "Epoch 413/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.9036 - val_accuracy: 0.7255\n",
            "Epoch 414/750\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0803 - val_accuracy: 0.6863\n",
            "Epoch 415/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0537 - val_accuracy: 0.6667\n",
            "Epoch 416/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9919 - val_accuracy: 0.6961\n",
            "Epoch 417/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.9685 - val_accuracy: 0.7157\n",
            "Epoch 418/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.2921 - val_accuracy: 0.6765\n",
            "Epoch 419/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.9710 - val_accuracy: 0.7157\n",
            "Epoch 420/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.9147 - val_accuracy: 0.7255\n",
            "Epoch 421/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1044 - val_accuracy: 0.7059\n",
            "Epoch 422/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1492 - val_accuracy: 0.7059\n",
            "Epoch 423/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.7993 - val_accuracy: 0.7549\n",
            "Epoch 424/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.2905 - val_accuracy: 0.6569\n",
            "Epoch 425/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.1724 - val_accuracy: 0.6961\n",
            "Epoch 426/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0327 - val_accuracy: 0.7059\n",
            "Epoch 427/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 1.0899 - val_accuracy: 0.6863\n",
            "Epoch 428/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.9096 - val_accuracy: 0.7157\n",
            "Epoch 429/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.8983 - val_accuracy: 0.7353\n",
            "Epoch 430/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.9090 - val_accuracy: 0.7647\n",
            "Epoch 431/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.9868 - val_accuracy: 0.7451\n",
            "Epoch 432/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0144 - accuracy: 0.9941 - val_loss: 1.1362 - val_accuracy: 0.6961\n",
            "Epoch 433/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0132 - accuracy: 0.9971 - val_loss: 1.2275 - val_accuracy: 0.6863\n",
            "Epoch 434/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.0574 - val_accuracy: 0.7255\n",
            "Epoch 435/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.0910 - val_accuracy: 0.6765\n",
            "Epoch 436/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.0850 - val_accuracy: 0.6765\n",
            "Epoch 437/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.0066 - val_accuracy: 0.7255\n",
            "Epoch 438/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.0577 - val_accuracy: 0.7157\n",
            "Epoch 439/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0117 - accuracy: 0.9941 - val_loss: 0.8196 - val_accuracy: 0.7255\n",
            "Epoch 440/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9484 - val_accuracy: 0.7059\n",
            "Epoch 441/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0283 - val_accuracy: 0.7255\n",
            "Epoch 442/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 1.0525 - val_accuracy: 0.7157\n",
            "Epoch 443/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.0908 - val_accuracy: 0.6863\n",
            "Epoch 444/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.9562 - val_accuracy: 0.7059\n",
            "Epoch 445/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9586 - val_accuracy: 0.7255\n",
            "Epoch 446/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.0355 - val_accuracy: 0.7059\n",
            "Epoch 447/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.1955 - val_accuracy: 0.6863\n",
            "Epoch 448/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.8817 - val_accuracy: 0.7647\n",
            "Epoch 449/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.0461 - val_accuracy: 0.7059\n",
            "Epoch 450/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0660 - val_accuracy: 0.6961\n",
            "Epoch 451/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.1651 - val_accuracy: 0.7255\n",
            "Epoch 452/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.9911 - val_accuracy: 0.6961\n",
            "Epoch 453/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9587 - val_accuracy: 0.7255\n",
            "Epoch 454/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.8414 - val_accuracy: 0.7157\n",
            "Epoch 455/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.1654 - val_accuracy: 0.7157\n",
            "Epoch 456/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.2226 - val_accuracy: 0.6765\n",
            "Epoch 457/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0159 - accuracy: 0.9971 - val_loss: 0.9519 - val_accuracy: 0.6961\n",
            "Epoch 458/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.0754 - val_accuracy: 0.6863\n",
            "Epoch 459/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.9539 - val_accuracy: 0.7157\n",
            "Epoch 460/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.9270 - val_accuracy: 0.7255\n",
            "Epoch 461/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.9603 - val_accuracy: 0.7157\n",
            "Epoch 462/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9870 - val_accuracy: 0.7059\n",
            "Epoch 463/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.8664 - val_accuracy: 0.7255\n",
            "Epoch 464/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.1279 - val_accuracy: 0.6961\n",
            "Epoch 465/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.1629 - val_accuracy: 0.6667\n",
            "Epoch 466/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9659 - val_accuracy: 0.7451\n",
            "Epoch 467/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.1965 - val_accuracy: 0.6569\n",
            "Epoch 468/750\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.9558 - val_accuracy: 0.7157\n",
            "Epoch 469/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.8419 - val_accuracy: 0.7451\n",
            "Epoch 470/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9520 - val_accuracy: 0.7157\n",
            "Epoch 471/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0140 - val_accuracy: 0.6961\n",
            "Epoch 472/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.1291 - val_accuracy: 0.6765\n",
            "Epoch 473/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.9083 - val_accuracy: 0.7157\n",
            "Epoch 474/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 1.1610 - val_accuracy: 0.6961\n",
            "Epoch 475/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0061 - accuracy: 0.9971 - val_loss: 1.0971 - val_accuracy: 0.7059\n",
            "Epoch 476/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.9421 - val_accuracy: 0.7255\n",
            "Epoch 477/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1386 - val_accuracy: 0.6667\n",
            "Epoch 478/750\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.9753 - val_accuracy: 0.7353\n",
            "Epoch 479/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9685 - val_accuracy: 0.6863\n",
            "Epoch 480/750\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.8912 - val_accuracy: 0.7451\n",
            "Epoch 481/750\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2208 - val_accuracy: 0.6765\n",
            "Epoch 482/750\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.8927 - val_accuracy: 0.7255\n",
            "Epoch 483/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.2026 - val_accuracy: 0.6569\n",
            "Epoch 484/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.1434 - val_accuracy: 0.6961\n",
            "Epoch 485/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.2352 - val_accuracy: 0.6863\n",
            "Epoch 486/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0317 - val_accuracy: 0.6961\n",
            "Epoch 487/750\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.8783 - val_accuracy: 0.7451\n",
            "Epoch 488/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9926 - val_accuracy: 0.7451\n",
            "Epoch 489/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.0165 - val_accuracy: 0.7059\n",
            "Epoch 490/750\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.7513 - val_accuracy: 0.7353\n",
            "Epoch 491/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 1.0257 - val_accuracy: 0.7255\n",
            "Epoch 492/750\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9246 - val_accuracy: 0.6863\n",
            "Epoch 493/750\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.9548 - val_accuracy: 0.7255\n",
            "Epoch 494/750\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.9833 - val_accuracy: 0.7157\n",
            "Epoch 495/750\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.2020 - val_accuracy: 0.7059\n",
            "Epoch 496/750\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.0066 - val_accuracy: 0.7059\n",
            "Epoch 497/750\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.9872 - val_accuracy: 0.6961\n",
            "Epoch 498/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.9802 - val_accuracy: 0.6863\n",
            "Epoch 499/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0118 - accuracy: 0.9971 - val_loss: 0.9259 - val_accuracy: 0.7059\n",
            "Epoch 500/750\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0127 - accuracy: 0.9971 - val_loss: 0.9111 - val_accuracy: 0.7451\n",
            "Epoch 501/750\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.8716 - val_accuracy: 0.7549\n",
            "Epoch 502/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.3798 - val_accuracy: 0.6667\n",
            "Epoch 503/750\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1273 - val_accuracy: 0.6765\n",
            "Epoch 504/750\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0065 - accuracy: 0.9971 - val_loss: 1.0146 - val_accuracy: 0.7059\n",
            "Epoch 505/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.2237 - val_accuracy: 0.6961\n",
            "Epoch 506/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.1738 - val_accuracy: 0.7157\n",
            "Epoch 507/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1667 - val_accuracy: 0.6961\n",
            "Epoch 508/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1234 - val_accuracy: 0.6765\n",
            "Epoch 509/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0974 - val_accuracy: 0.6961\n",
            "Epoch 510/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.7291 - val_accuracy: 0.7745\n",
            "Epoch 511/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0331 - val_accuracy: 0.7157\n",
            "Epoch 512/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1228 - val_accuracy: 0.7059\n",
            "Epoch 513/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.9685 - val_accuracy: 0.7353\n",
            "Epoch 514/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0499 - val_accuracy: 0.7353\n",
            "Epoch 515/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.0899 - val_accuracy: 0.7059\n",
            "Epoch 516/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.9031 - val_accuracy: 0.7451\n",
            "Epoch 517/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.0112 - val_accuracy: 0.7353\n",
            "Epoch 518/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 1.0203 - val_accuracy: 0.7255\n",
            "Epoch 519/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.2181 - val_accuracy: 0.6863\n",
            "Epoch 520/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.2177 - val_accuracy: 0.6961\n",
            "Epoch 521/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3516 - val_accuracy: 0.6765\n",
            "Epoch 522/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.1163 - val_accuracy: 0.6961\n",
            "Epoch 523/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 1.2299 - val_accuracy: 0.6863\n",
            "Epoch 524/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.9025 - val_accuracy: 0.7549\n",
            "Epoch 525/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 1.3213 - val_accuracy: 0.6863\n",
            "Epoch 526/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 1.0462 - val_accuracy: 0.7059\n",
            "Epoch 527/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.1182 - val_accuracy: 0.7157\n",
            "Epoch 528/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.0655 - val_accuracy: 0.6961\n",
            "Epoch 529/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 1.3054 - val_accuracy: 0.6765\n",
            "Epoch 530/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 1.1692 - val_accuracy: 0.6765\n",
            "Epoch 531/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0925 - val_accuracy: 0.6863\n",
            "Epoch 532/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.8483 - val_accuracy: 0.7353\n",
            "Epoch 533/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.9319 - val_accuracy: 0.6961\n",
            "Epoch 534/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.1679 - val_accuracy: 0.7157\n",
            "Epoch 535/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8322 - val_accuracy: 0.7647\n",
            "Epoch 536/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.9645 - val_accuracy: 0.7451\n",
            "Epoch 537/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.1077 - val_accuracy: 0.6863\n",
            "Epoch 538/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0147 - accuracy: 0.9941 - val_loss: 1.1215 - val_accuracy: 0.6765\n",
            "Epoch 539/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 1.3078 - val_accuracy: 0.6569\n",
            "Epoch 540/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.9465 - val_accuracy: 0.7157\n",
            "Epoch 541/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.9338 - val_accuracy: 0.7255\n",
            "Epoch 542/750\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0068 - accuracy: 0.9971 - val_loss: 1.1991 - val_accuracy: 0.6863\n",
            "Epoch 543/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.9908 - val_accuracy: 0.7255\n",
            "Epoch 544/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.1015 - val_accuracy: 0.6863\n",
            "Epoch 545/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.0865 - val_accuracy: 0.6863\n",
            "Epoch 546/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 1.1390 - val_accuracy: 0.7059\n",
            "Epoch 547/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.1865 - val_accuracy: 0.6961\n",
            "Epoch 548/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0419 - val_accuracy: 0.7059\n",
            "Epoch 549/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2406 - val_accuracy: 0.6863\n",
            "Epoch 550/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.3456 - val_accuracy: 0.6569\n",
            "Epoch 551/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.2436 - val_accuracy: 0.6667\n",
            "Epoch 552/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0076 - accuracy: 0.9941 - val_loss: 1.1252 - val_accuracy: 0.7059\n",
            "Epoch 553/750\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0097 - accuracy: 0.9971 - val_loss: 0.9838 - val_accuracy: 0.7255\n",
            "Epoch 554/750\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.8958 - val_accuracy: 0.7549\n",
            "Epoch 555/750\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.0025 - val_accuracy: 0.7451\n",
            "Epoch 556/750\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 1.1065 - val_accuracy: 0.7059\n",
            "Epoch 557/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.0188 - val_accuracy: 0.7059\n",
            "Epoch 558/750\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.0090 - val_accuracy: 0.7157\n",
            "Epoch 559/750\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.1058 - val_accuracy: 0.7157\n",
            "Epoch 560/750\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.8773 - val_accuracy: 0.7549\n",
            "Epoch 561/750\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0651 - val_accuracy: 0.7059\n",
            "Epoch 562/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.0124 - val_accuracy: 0.7451\n",
            "Epoch 563/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.8883 - val_accuracy: 0.7549\n",
            "Epoch 564/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.7353\n",
            "Epoch 565/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.9212 - val_accuracy: 0.7647\n",
            "Epoch 566/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.8718 - val_accuracy: 0.7451\n",
            "Epoch 567/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3015 - val_accuracy: 0.6667\n",
            "Epoch 568/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.4022 - val_accuracy: 0.5980\n",
            "Epoch 569/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9533 - val_accuracy: 0.7451\n",
            "Epoch 570/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.0364 - val_accuracy: 0.7157\n",
            "Epoch 571/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8409 - val_accuracy: 0.7745\n",
            "Epoch 572/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0139 - val_accuracy: 0.7353\n",
            "Epoch 573/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.0144 - val_accuracy: 0.7549\n",
            "Epoch 574/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1053 - val_accuracy: 0.7059\n",
            "Epoch 575/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0189 - val_accuracy: 0.7353\n",
            "Epoch 576/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9615 - val_accuracy: 0.7353\n",
            "Epoch 577/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.7676 - val_accuracy: 0.7647\n",
            "Epoch 578/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0732 - val_accuracy: 0.6961\n",
            "Epoch 579/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.1632 - val_accuracy: 0.6961\n",
            "Epoch 580/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.0922 - val_accuracy: 0.7157\n",
            "Epoch 581/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.8327 - val_accuracy: 0.7549\n",
            "Epoch 582/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.9211 - val_accuracy: 0.7255\n",
            "Epoch 583/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.2015 - val_accuracy: 0.6667\n",
            "Epoch 584/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0073 - accuracy: 0.9971 - val_loss: 0.9821 - val_accuracy: 0.7353\n",
            "Epoch 585/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.8057 - val_accuracy: 0.7451\n",
            "Epoch 586/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1193 - val_accuracy: 0.6961\n",
            "Epoch 587/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.3319 - val_accuracy: 0.6863\n",
            "Epoch 588/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.0364 - val_accuracy: 0.7157\n",
            "Epoch 589/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.9854 - val_accuracy: 0.7255\n",
            "Epoch 590/750\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.9871 - val_accuracy: 0.7353\n",
            "Epoch 591/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.9908 - val_accuracy: 0.7353\n",
            "Epoch 592/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3197 - val_accuracy: 0.6667\n",
            "Epoch 593/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1332 - val_accuracy: 0.6961\n",
            "Epoch 594/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1927 - val_accuracy: 0.6863\n",
            "Epoch 595/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0065 - accuracy: 0.9971 - val_loss: 1.1055 - val_accuracy: 0.7059\n",
            "Epoch 596/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.0898 - val_accuracy: 0.6961\n",
            "Epoch 597/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 1.1855 - val_accuracy: 0.7157\n",
            "Epoch 598/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.9718 - val_accuracy: 0.7451\n",
            "Epoch 599/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0189 - accuracy: 0.9912 - val_loss: 0.9451 - val_accuracy: 0.7647\n",
            "Epoch 600/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0144 - accuracy: 0.9971 - val_loss: 0.9528 - val_accuracy: 0.7353\n",
            "Epoch 601/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0232 - accuracy: 0.9971 - val_loss: 0.9001 - val_accuracy: 0.7353\n",
            "Epoch 602/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0510 - accuracy: 0.9853 - val_loss: 1.3369 - val_accuracy: 0.6667\n",
            "Epoch 603/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0327 - accuracy: 0.9853 - val_loss: 0.9853 - val_accuracy: 0.7255\n",
            "Epoch 604/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.7493 - val_accuracy: 0.7745\n",
            "Epoch 605/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.9534 - val_accuracy: 0.7157\n",
            "Epoch 606/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0267 - accuracy: 0.9941 - val_loss: 0.9039 - val_accuracy: 0.7255\n",
            "Epoch 607/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.8987 - val_accuracy: 0.7451\n",
            "Epoch 608/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0165 - accuracy: 0.9971 - val_loss: 1.0216 - val_accuracy: 0.7255\n",
            "Epoch 609/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0198 - accuracy: 0.9912 - val_loss: 1.0900 - val_accuracy: 0.6961\n",
            "Epoch 610/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0118 - accuracy: 0.9971 - val_loss: 0.9949 - val_accuracy: 0.7255\n",
            "Epoch 611/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.1264 - val_accuracy: 0.6765\n",
            "Epoch 612/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0172 - accuracy: 0.9971 - val_loss: 0.8597 - val_accuracy: 0.7157\n",
            "Epoch 613/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0134 - accuracy: 0.9971 - val_loss: 0.8294 - val_accuracy: 0.7451\n",
            "Epoch 614/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0160 - accuracy: 0.9941 - val_loss: 0.9495 - val_accuracy: 0.6667\n",
            "Epoch 615/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 1.0507 - val_accuracy: 0.6765\n",
            "Epoch 616/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.8387 - val_accuracy: 0.7255\n",
            "Epoch 617/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.9162 - val_accuracy: 0.7255\n",
            "Epoch 618/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.2303 - val_accuracy: 0.6667\n",
            "Epoch 619/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.9410 - val_accuracy: 0.7353\n",
            "Epoch 620/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.9180 - val_accuracy: 0.7353\n",
            "Epoch 621/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.9584 - val_accuracy: 0.7255\n",
            "Epoch 622/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.8149 - val_accuracy: 0.7647\n",
            "Epoch 623/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 1.0706 - val_accuracy: 0.6961\n",
            "Epoch 624/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.9376 - val_accuracy: 0.7157\n",
            "Epoch 625/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.8725 - val_accuracy: 0.7451\n",
            "Epoch 626/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.9231 - val_accuracy: 0.7353\n",
            "Epoch 627/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8791 - val_accuracy: 0.7353\n",
            "Epoch 628/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.9584 - val_accuracy: 0.7059\n",
            "Epoch 629/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.9535 - val_accuracy: 0.7255\n",
            "Epoch 630/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.2061 - val_accuracy: 0.7059\n",
            "Epoch 631/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.8618 - val_accuracy: 0.7745\n",
            "Epoch 632/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.9026 - val_accuracy: 0.7451\n",
            "Epoch 633/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.7972 - val_accuracy: 0.7647\n",
            "Epoch 634/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8954 - val_accuracy: 0.7353\n",
            "Epoch 635/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.9459 - val_accuracy: 0.7255\n",
            "Epoch 636/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2241 - val_accuracy: 0.6765\n",
            "Epoch 637/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.9174 - val_accuracy: 0.7255\n",
            "Epoch 638/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8139 - val_accuracy: 0.7549\n",
            "Epoch 639/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.8879 - val_accuracy: 0.7549\n",
            "Epoch 640/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1678 - val_accuracy: 0.7059\n",
            "Epoch 641/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0060 - accuracy: 0.9971 - val_loss: 1.0417 - val_accuracy: 0.7157\n",
            "Epoch 642/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.9131 - val_accuracy: 0.7549\n",
            "Epoch 643/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.9102 - val_accuracy: 0.7451\n",
            "Epoch 644/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.9266 - val_accuracy: 0.7549\n",
            "Epoch 645/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0397 - val_accuracy: 0.7353\n",
            "Epoch 646/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1252 - val_accuracy: 0.6961\n",
            "Epoch 647/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9807 - val_accuracy: 0.7353\n",
            "Epoch 648/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.2919 - val_accuracy: 0.6569\n",
            "Epoch 649/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.9768 - val_accuracy: 0.7451\n",
            "Epoch 650/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.8697 - val_accuracy: 0.7647\n",
            "Epoch 651/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.1059 - val_accuracy: 0.7157\n",
            "Epoch 652/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.1749 - val_accuracy: 0.7059\n",
            "Epoch 653/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.0552 - val_accuracy: 0.6961\n",
            "Epoch 654/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8515 - val_accuracy: 0.7353\n",
            "Epoch 655/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.0944 - val_accuracy: 0.6961\n",
            "Epoch 656/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.8939 - val_accuracy: 0.7549\n",
            "Epoch 657/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.0098 - val_accuracy: 0.7157\n",
            "Epoch 658/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0170 - val_accuracy: 0.6961\n",
            "Epoch 659/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9864 - val_accuracy: 0.7353\n",
            "Epoch 660/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.8692 - val_accuracy: 0.7647\n",
            "Epoch 661/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.7647\n",
            "Epoch 662/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.8998 - val_accuracy: 0.7451\n",
            "Epoch 663/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9106 - val_accuracy: 0.7451\n",
            "Epoch 664/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1362 - val_accuracy: 0.7255\n",
            "Epoch 665/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.9924 - val_accuracy: 0.7255\n",
            "Epoch 666/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.9754 - val_accuracy: 0.7353\n",
            "Epoch 667/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0217 - val_accuracy: 0.7255\n",
            "Epoch 668/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.0634 - val_accuracy: 0.7059\n",
            "Epoch 669/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8845 - val_accuracy: 0.7451\n",
            "Epoch 670/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.0732 - val_accuracy: 0.7353\n",
            "Epoch 671/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.0071 - val_accuracy: 0.6765\n",
            "Epoch 672/750\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8923 - val_accuracy: 0.7549\n",
            "Epoch 673/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.8574 - val_accuracy: 0.7451\n",
            "Epoch 674/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8994 - val_accuracy: 0.7353\n",
            "Epoch 675/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.9634 - val_accuracy: 0.7255\n",
            "Epoch 676/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1410 - val_accuracy: 0.7059\n",
            "Epoch 677/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.9493 - val_accuracy: 0.7157\n",
            "Epoch 678/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1074 - val_accuracy: 0.6863\n",
            "Epoch 679/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9581 - val_accuracy: 0.7353\n",
            "Epoch 680/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0588 - val_accuracy: 0.6961\n",
            "Epoch 681/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 0.7255\n",
            "Epoch 682/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.7682 - val_accuracy: 0.7549\n",
            "Epoch 683/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.9578 - val_accuracy: 0.6961\n",
            "Epoch 684/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.9001 - val_accuracy: 0.7549\n",
            "Epoch 685/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.8017 - val_accuracy: 0.7941\n",
            "Epoch 686/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1135 - val_accuracy: 0.6765\n",
            "Epoch 687/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.9261 - val_accuracy: 0.7353\n",
            "Epoch 688/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1016 - val_accuracy: 0.7059\n",
            "Epoch 689/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1107 - val_accuracy: 0.7255\n",
            "Epoch 690/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9261 - val_accuracy: 0.7157\n",
            "Epoch 691/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2031 - val_accuracy: 0.6863\n",
            "Epoch 692/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0694 - val_accuracy: 0.7451\n",
            "Epoch 693/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.2468 - val_accuracy: 0.6569\n",
            "Epoch 694/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.8607 - val_accuracy: 0.7745\n",
            "Epoch 695/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.8369 - val_accuracy: 0.7745\n",
            "Epoch 696/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8749 - val_accuracy: 0.7451\n",
            "Epoch 697/750\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1061 - val_accuracy: 0.6961\n",
            "Epoch 698/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9316 - val_accuracy: 0.7255\n",
            "Epoch 699/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9305 - val_accuracy: 0.7353\n",
            "Epoch 700/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.9763 - val_accuracy: 0.7353\n",
            "Epoch 701/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.1093 - val_accuracy: 0.7059\n",
            "Epoch 702/750\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.3609 - val_accuracy: 0.6569\n",
            "Epoch 703/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0949 - val_accuracy: 0.7353\n",
            "Epoch 704/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.8895 - val_accuracy: 0.7353\n",
            "Epoch 705/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1492 - val_accuracy: 0.6863\n",
            "Epoch 706/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.0647 - val_accuracy: 0.7451\n",
            "Epoch 707/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0393 - val_accuracy: 0.7255\n",
            "Epoch 708/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.8339 - val_accuracy: 0.7549\n",
            "Epoch 709/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0057 - accuracy: 0.9971 - val_loss: 0.9924 - val_accuracy: 0.7353\n",
            "Epoch 710/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0058 - accuracy: 0.9971 - val_loss: 1.0072 - val_accuracy: 0.7353\n",
            "Epoch 711/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.9050 - val_accuracy: 0.7353\n",
            "Epoch 712/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.9757 - val_accuracy: 0.7255\n",
            "Epoch 713/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3282 - val_accuracy: 0.6863\n",
            "Epoch 714/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.1900 - val_accuracy: 0.7255\n",
            "Epoch 715/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0066 - accuracy: 0.9971 - val_loss: 1.1216 - val_accuracy: 0.7157\n",
            "Epoch 716/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0193 - accuracy: 0.9971 - val_loss: 1.1984 - val_accuracy: 0.6765\n",
            "Epoch 717/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.4837 - val_accuracy: 0.6078\n",
            "Epoch 718/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1597 - val_accuracy: 0.6961\n",
            "Epoch 719/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0200 - accuracy: 0.9912 - val_loss: 1.0162 - val_accuracy: 0.7451\n",
            "Epoch 720/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 1.1492 - val_accuracy: 0.7255\n",
            "Epoch 721/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 1.1504 - val_accuracy: 0.6961\n",
            "Epoch 722/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.9354 - val_accuracy: 0.7549\n",
            "Epoch 723/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0209 - accuracy: 0.9941 - val_loss: 0.9598 - val_accuracy: 0.7549\n",
            "Epoch 724/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.9379 - val_accuracy: 0.7353\n",
            "Epoch 725/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.2742 - val_accuracy: 0.6667\n",
            "Epoch 726/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 1.2054 - val_accuracy: 0.6961\n",
            "Epoch 727/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0335 - accuracy: 0.9912 - val_loss: 1.2561 - val_accuracy: 0.6569\n",
            "Epoch 728/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0326 - accuracy: 0.9882 - val_loss: 1.3395 - val_accuracy: 0.7059\n",
            "Epoch 729/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 1.0005 - val_accuracy: 0.7255\n",
            "Epoch 730/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0169 - accuracy: 0.9971 - val_loss: 1.1438 - val_accuracy: 0.6765\n",
            "Epoch 731/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.2966 - val_accuracy: 0.6569\n",
            "Epoch 732/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.8549 - val_accuracy: 0.7451\n",
            "Epoch 733/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.8289 - val_accuracy: 0.7059\n",
            "Epoch 734/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.0409 - val_accuracy: 0.7157\n",
            "Epoch 735/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.9821 - val_accuracy: 0.7059\n",
            "Epoch 736/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.0459 - val_accuracy: 0.6765\n",
            "Epoch 737/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.1552 - val_accuracy: 0.7059\n",
            "Epoch 738/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.9310 - val_accuracy: 0.7647\n",
            "Epoch 739/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.2504 - val_accuracy: 0.6765\n",
            "Epoch 740/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.9097 - val_accuracy: 0.7843\n",
            "Epoch 741/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0137 - accuracy: 0.9971 - val_loss: 1.0913 - val_accuracy: 0.7353\n",
            "Epoch 742/750\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 0.0218 - accuracy: 0.9971 - val_loss: 1.4412 - val_accuracy: 0.6765\n",
            "Epoch 743/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0446 - accuracy: 0.9853 - val_loss: 1.0518 - val_accuracy: 0.6961\n",
            "Epoch 744/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0385 - accuracy: 0.9882 - val_loss: 0.9734 - val_accuracy: 0.7353\n",
            "Epoch 745/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0414 - accuracy: 0.9912 - val_loss: 0.9615 - val_accuracy: 0.7255\n",
            "Epoch 746/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0470 - accuracy: 0.9882 - val_loss: 0.8513 - val_accuracy: 0.7353\n",
            "Epoch 747/750\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 0.0741 - accuracy: 0.9735 - val_loss: 1.1982 - val_accuracy: 0.6667\n",
            "Epoch 748/750\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0503 - accuracy: 0.9882 - val_loss: 0.8329 - val_accuracy: 0.7549\n",
            "Epoch 749/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0437 - accuracy: 0.9853 - val_loss: 0.9998 - val_accuracy: 0.7451\n",
            "Epoch 750/750\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 0.0277 - accuracy: 0.9971 - val_loss: 1.0848 - val_accuracy: 0.7059\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)\n",
        "fittedModel = model.fit(TrainData1, TrainLabel1, batch_size = 64, epochs = 750, \n",
        "                        validation_data=(ValidData1, ValidLabel1))\n",
        "                       \n",
        "                        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "g_hybrg_IzDG",
        "outputId": "80cf6793-70ed-4065-9fb3-ea4eaa760d0a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(fittedModel.history['accuracy'])\n",
        "plt.plot(fittedModel.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "AuYMerO9dZoZ",
        "outputId": "6e1250ef-aed4-461e-bc60-5994fe427938"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(fittedModel.history['loss'])\n",
        "plt.plot(fittedModel.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7T353jHEgfu",
        "outputId": "277203d0-049f-4dbe-9f2b-a0783c31da41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6731372584501902\n"
          ]
        }
      ],
      "source": [
        "print(np.mean(fittedModel.history['val_accuracy']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6qlg0WyiRkj",
        "outputId": "d79fad36-477a-4a3a-9f5d-ac0b3c8ee18c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 165ms/step - loss: 0.6096 - accuracy: 0.8333\n",
            "(12, 22, 1000, 1) (12, 4)\n"
          ]
        }
      ],
      "source": [
        "model.evaluate(TestData1, TestLabel1)\n",
        "print(TestData1.shape,TestLabel1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrFPKtJFC8Zj",
        "outputId": "47d5ea16-041c-49f5-c34b-9d93c9f8981d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 0 2 3 0 3 3 0 2] [0 1 0 0 0 2 0 0 3 3 0 0]\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(TestData1)\n",
        "pred_classes = np.argmax(predictions, axis = 1)\n",
        "actual_classes = np.argmax(TestLabel1, axis = 1)\n",
        "print(pred_classes, actual_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "V1iVImOUbxez",
        "outputId": "2625af15-2642-4e4c-da93-325e3e430916"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 83.33333333333334 %\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "from sklearn import metrics\n",
        "\n",
        "confusion_matrix = metrics.confusion_matrix(actual_classes, pred_classes)\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['Left','Right','Foot','Tongue'])\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()\n",
        "Accuracy = metrics.accuracy_score(actual_classes, pred_classes)\n",
        "print('The accuracy is',Accuracy*100, '%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}